{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_crawler import TwitterCrawler\n",
    "my_token = 'AAAAAAAAAAAAAAAAAAAAADRFOwEAAAAAaTp%2Bdd1OhobYMYb5ExPXm7IL6RA%3DDHknH402gOXoegUGxNtpC6giIjdackRLtdRx6tjrnnLeFN1ntT'\n",
    "my_twitter_crawler = TwitterCrawler(bearer_token= my_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/anyuser/status/1466035318365294603'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterCrawler.get_url_by_tweet_id(\"1466035318365294603\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = \"1470753200311517189\" #\"1108157488581562373\"\n",
    "my_twitter_crawler.create_url_tweet_id(tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"fun\"\n",
    "start_time =\"2022-03-10T00:00:00.000Z\"\n",
    "end_time = \"2022-03-11T00:00:00.000Z\"\n",
    "max_results = 10 #minimum 10 and maximum 100 !\n",
    "\n",
    "my_twitter_crawler.search_recent_by_keyword(keyword, start_time,end_time, max_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing  search_recent_by_keyword\n",
    "\n",
    "\n",
    "all_key_opinion_leader_names = [\"DavidDavisMP\"]\n",
    "\n",
    "\n",
    "#all_key_opinion_leader_names = [\"DominicCumins\", \"darrengrimes_\", \"PhilipHammondUK\",\"roymadpis789\"]\n",
    "#MakhoulRawaa\n",
    "start_time = \"2015-12-7T00:00:00Z\"\n",
    "end_time = \"2021-12-04T00:00:00Z\"\n",
    "max_results = 500\n",
    "limit_amount_of_returned_tweets = 1000000\n",
    "############################################################################################\n",
    "\n",
    "#### we don't want to get data on key opinion leaders that we already searched for their tweets!\n",
    "# thus we first need to see which of the users that are inserted in the list are **not** in the files we already have:\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#making the data and log dir\n",
    "dir_name = \"key_opinion_leaders_tweets_tables_beta\"\n",
    "#dir_log_name = \"log_key_opinion_leaders\"\n",
    "#path_for_log_dir = os.path.join(dir_name, dir_log_name)\n",
    "\n",
    "import os.path\n",
    "try:\n",
    "    os.mkdir(dir_name)\n",
    "    print(\"creating directory\", dir_name, \"to insert all the tables of all the key opinion leaders\")\n",
    "except:\n",
    "    print(\"The dir\", dir_name ,\"already exist\")\n",
    "\n",
    "    \n",
    "mypath = \"key_opinion_leaders_tweets_tables_beta\"\n",
    "users_we_have_data = [f.split(\".\")[0] for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "key_opinion_leader_names = list(set(all_key_opinion_leader_names) - set(users_we_have_data))\n",
    "print(\"Users to search their tweets:\",key_opinion_leader_names)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Users we already have data on:\",list(set(all_key_opinion_leader_names).intersection(users_we_have_data)))\n",
    "\n",
    "\n",
    "json_responses_list, num_of_returned_twweets, next_token = \\\n",
    "my_twitter_crawler.return_tweets_of_key_opinion_leader(query=\"\", user_name=\"DavidDavisMP\",\n",
    "                                        start_time = \"2015-12-7T00:00:00Z\",\n",
    "                                        end_time = \"2021-12-26T00:00:00Z\",\n",
    "                                        max_results = 10, evaluate_last_token = False,\n",
    "                                        limit_amount_of_returned_tweets = 50,\n",
    "                                       verbose_10 = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "tokens_location = \"/Users/michaelkobaivanov/Library/Mobile Documents/com~apple~CloudDocs/year3/brexit-package/key_opinion_leaders_tweets_tables_beta/log_key_opinion_leaders/DavidDavisMP/tokens.txt\"\n",
    "\n",
    "\n",
    "a_file = open(tokens_location, \"r\")\n",
    "lines = a_file.readlines()\n",
    "last_lines = lines[-2]\n",
    "next_token = last_lines[0:-1]\n",
    "a_file.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_twitter_crawler.return_tweets_of_key_opinion_leaders(query=\"\", user_names=[\"DavidDavisMP\",\"EndaKennyTD\",\"hilarybennmp\"],\n",
    "                                        start_time = \"2015-12-7T00:00:00Z\",\n",
    "                                        end_time = \"2021-12-26T00:00:00Z\",\n",
    "                                        max_results = 10, evaluate_last_token = False,\n",
    "                                        limit_amount_of_returned_tweets = 50,\n",
    "                                       verbose_10 = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_twitter_crawler.get_tweets_by_tweet_ids(tweet_ids= [\"682715594110689280\",\"682715872205651968\", \"682716086681382912\", \"682720118401581056\"],\n",
    "json_tweets_output_folder = \"json_tweets_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bringing retweets of 1473447665757310980\n",
      "The dir conversation_trees already exist\n",
      "The dir conversation_trees/conv_tree_for_1473447665757310980 already exist\n",
      "The dir conversation_trees/conv_tree_for_1473447665757310980/log_retweets_for_tweet_id_1473447665757310980 already exist\n",
      "1 Got from twitter 10 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "token to insert: 7140dibdnow9c7btw480y1pt2iosnkae791k6wk5880fo\n",
      "token to insert: 7140dibdnow9c7btw480y1pi734vtidfash9us1zan2uq\n",
      "token to insert: 7140dibdnow9c7btw480y1p7d5508zqaqt2jy14t1okz8\n",
      "token to insert: 7140dibdnow9c7btw480y1olzuuxz9dhgkxage8eaxmbb\n",
      "token to insert: 7140dibdnow9c7btw480y1ob8x998r2oqnwbou7oaki7m\n",
      "token to insert: 7140dibdnow9c7btw480y1o0gj5q9n0gltzt49u867a5t\n",
      "token to insert: 7140dibdnow9c7btw480y1o02tupyp4qq9mn0f6ai0hf4\n",
      "token to insert: 7140dibdnow9c7btw480xzldr43191w17kbus2kwc3dx0\n",
      "token to insert: 7140dibdnow9c7btw480xzl2yqf77gqc89ze633hbsri0\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 100 returned tweets and limited the function to get 100 tweets\n",
      "100\n",
      "---------------------------------------------------------------\n",
      "Bringing retweets of 1506035877751005193\n",
      "The dir conversation_trees already exist\n",
      "creating directory conversation_trees/conv_tree_for_1506035877751005193 to insert all the retweets of the given tweet-id\n",
      "creating directory conversation_trees/conv_tree_for_1506035877751005193/log_retweets_for_tweet_id_1506035877751005193 to insert all the logs of the retweets for the tweet id -  1506035877751005193\n",
      "1 Got from twitter 10 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "token to insert: 7140dibdnow9c7btw480y3s4ou41g8f7vacfxz0ge4soh\n",
      "token to insert: 7140dibdnow9c7btw480y3s4nck4gvd44ffvripdlnbjp\n",
      "token to insert: 7140dibdnow9c7btw480y3s4nbx3z11ousds1zvq9jynk\n",
      "token to insert: 7140dibdnow9c7btw480y3s4nb2588ophk8gg3rjbgeuu\n",
      "token to insert: 7140dibdnow9c7btw480y1q3zikmp5cb56nf1jqgx86yb\n",
      "token to insert: 7140dibdnow9c7btw480y1q3zi55bog65cawd5uut52d4\n",
      "token to insert: 7140dibdnow9c7btw480y1q3zhpr6prt2znfv7yq8t0s5\n",
      "token to insert: 7140dibdnow9c7btw480y1q3zhams1fhhp1b9rqzav29g\n",
      "token to insert: 7140dibdnow9c7btw480y1q3zh2x5vwrisszssiu5m2wg\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 100 returned tweets and limited the function to get 100 tweets\n",
      "100\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tweet_id = [\"1473447665757310980\",\"1506035877751005193\"]\n",
    "\n",
    "my_twitter_crawler.return_retweets_by_tweet_ids(tweet_ids=tweet_id,\n",
    "                                    max_results = 10, evaluate_last_token = False,\n",
    "                                    limit_amount_of_returned_retweets = 100,\n",
    "                                   verbose = True, dir_tree_name = \"conversation_trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d3c51dcc737e3b755df5c6775e1f16aeea3921fc151dde7ea513fa4bec4ea0c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('brexit-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
